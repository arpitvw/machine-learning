{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import time\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate=0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "2\n",
      "Training data size:  (2, 2)\n",
      "(np.dot(dz3,np.transpose(a2))) (10, 12)\n",
      "loss: 7.97433725355e-09\n",
      "a4 staring: [ 0.5  0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_label=np.array([0,1]) #np.array([0,2,0,3,1,5,6,4,2,5]*10)\n",
    "print (Y_label.shape)\n",
    "X_training_data=np.array([[0., 0.], [1., 1.]]) #np.random.uniform(1,500,size=(7,100))\n",
    "c=np.zeros((2,2))\n",
    "c[np.arange(2),Y_label]=1\n",
    "#print(\"test\",c)\n",
    "#print(\"test\",np.transpose(c)[9,:])\n",
    "c=np.transpose(c)\n",
    "training_count=X_training_data.shape[1]\n",
    "#features=X_training_data.shape[0]\n",
    "print (training_count)\n",
    "\n",
    "\n",
    "print ('Training data size: ',X_training_data.shape) \n",
    "#print ('Describe: ',df.describe())\n",
    "Features=X_training_data.shape[0]\n",
    "#dict_layers={1:15,2:12,3:10,4:7}\n",
    "\n",
    "def sigmoid(x,driv=False):\n",
    "    if driv:\n",
    "        return x*(1-x)\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    t=np.exp(x)\n",
    "    sum1=np.sum(t,axis=0)\n",
    "    return t/sum1\n",
    "\n",
    "def weights(neuron,input_features):\n",
    "    return (np.random.uniform(3,1,size=(neuron,input_features)))\n",
    "\n",
    "def hypothesis(weights,input_features):\n",
    "    return np.dot(weights,input_features)\n",
    "def loss_function(actual_output,network_output):\n",
    "    return (np.multiply(actual_output,network_output))\n",
    "\n",
    "\n",
    "actualop=np.identity(7)\n",
    "\n",
    "w1=weights(15,Features)\n",
    "z1=hypothesis(w1,X_training_data)\n",
    "a1=sigmoid(z1)\n",
    "\n",
    "w2=weights(12,15)\n",
    "z2=hypothesis(w2,a1)\n",
    "a2=sigmoid(z2)\n",
    "\n",
    "w3=weights(10,12)\n",
    "z3=hypothesis(w3,a2)\n",
    "a3=sigmoid(z3)\n",
    "\n",
    "w4=weights(2,10)\n",
    "z4=hypothesis(w4,a3)\n",
    "a4=sigmoid(z4)\n",
    "#print (\"a4 staring:\",a4)\n",
    "\n",
    "\n",
    "#print (\"a4:\",a4)\n",
    "print (\"(np.dot(dz3,np.transpose(a2)))\", np.dot(dz3,np.transpose(a2)).shape)\n",
    "\n",
    "for i in range(10):\n",
    "    output=softmax(a4)\n",
    "    \n",
    "    loss=loss_function(c,np.log(a4))#need to chnage as need to take log accroding to actualop\n",
    "    if i%100==0:\n",
    "        print (\"loss:\",np.sum(np.abs(loss))/training_count)\n",
    "    #a=np.log([a4[j,k]  for j in range(7) for k in range(7) if Y_label[j]==k])\n",
    "   # print (\"loss:\",loss.shape)\n",
    "    #print (\"a4:\",a4.shape)\n",
    "    da4=loss/a4\n",
    "    dz4=a4*(1-a4)\n",
    "    w4=w4-learning_rate*(np.dot(dz4,np.transpose(a3)))\n",
    "\n",
    "    da3=np.dot(np.transpose(w4),(a4*(1-a4)))\n",
    "    dz3=a3*(1-a3)\n",
    "    w3=w3-learning_rate*(np.dot(dz3,np.transpose(a2)))\n",
    "\n",
    "    da2=np.dot(np.transpose(w3),(a3*(1-a3)))\n",
    "    dz2=a2*(1-a2)\n",
    "    w2=w2-learning_rate*(np.dot(dz2,np.transpose(a1)))\n",
    "\n",
    "\n",
    "    da1=np.dot(np.transpose(w2),(a2*(1-a2)))\n",
    "    dz1=a1*(1-a1)\n",
    "    w1=w1-learning_rate*(np.dot(dz1,np.transpose(X_training_data)))\n",
    "    \n",
    "    z1=hypothesis(w1,X_training_data)\n",
    "    a1=sigmoid(z1)\n",
    "    \n",
    "    z2=hypothesis(w2,a1)\n",
    "    a2=sigmoid(z2)\n",
    "    \n",
    "    z3=hypothesis(w3,a2)\n",
    "    a3=sigmoid(z3)\n",
    "    \n",
    "    z4=hypothesis(w4,a3)\n",
    "    a4=sigmoid(z4)\n",
    "    \n",
    "    \n",
    "a=np.array([1,-2])\n",
    "\n",
    "z1=hypothesis(w1,a)\n",
    "a1=sigmoid(z1)\n",
    "\n",
    "\n",
    "z2=hypothesis(w2,a1)\n",
    "a2=sigmoid(z2)\n",
    "\n",
    "\n",
    "z3=hypothesis(w3,a2)\n",
    "a3=sigmoid(z3)\n",
    "\n",
    "z4=hypothesis(w4,a3)\n",
    "a4=sigmoid(z4)\n",
    "print (\"a4 staring:\",softmax(a4))\n",
    "\n",
    "X = [[0., 0.], [1., 1.]]\n",
    "y = [0, 1]\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=.0001,hidden_layer_sizes=(15,12,10,7), random_state=1,max_iter=1000)\n",
    "clf.fit(X_training_data, Y_label)\n",
    "clf.predict([1,-2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.18202126, -0.        , -1.18202126],\n",
       "       [-0.        , -0.        , -0.        ],\n",
       "       [-0.        , -1.15202559, -0.        ],\n",
       "       [-0.        , -0.        , -0.        ],\n",
       "       [-0.        , -0.        , -0.        ],\n",
       "       [-0.        , -0.        , -0.        ],\n",
       "       [-0.        , -0.        , -0.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01532759, -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
